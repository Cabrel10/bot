# Guide d'Optimisation Syst√©matique

## üîÑ Strat√©gies d'Optimisation

### 1. Recherche par Grille
```python
from trading.models import SystematicOptimizer

optimizer = SystematicOptimizer()

# Configuration de la grille
param_grid = {
    'hidden_layers': [[64], [128, 64]],
    'learning_rate': [0.01, 0.001],
    'batch_size': [64, 128]
}

# Fonction objectif
def objective(params):
    model = NeuralNetwork(**params)
    return model.evaluate(X_test, y_test)['sharpe_ratio']

# Ex√©cution de la recherche
best_params = optimizer.grid_search(
    param_grid=param_grid,
    objective_func=objective,
    n_trials=3  # R√©p√©titions pour la robustesse
)
```

### 2. Optimisation Bay√©sienne
```python
# D√©finition des bornes
param_bounds = [
    (0.0001, 0.1),  # learning_rate
    (32, 256)       # batch_size
]
param_names = ['learning_rate', 'batch_size']

# Ex√©cution de l'optimisation
best_params = optimizer.bayesian_optimization(
    param_bounds=param_bounds,
    param_names=param_names,
    objective_func=objective,
    n_calls=50
)
```

### 3. Analyse de Sensibilit√©
```python
# D√©finition du probl√®me
problem = {
    'num_vars': 3,
    'names': ['learning_rate', 'batch_size', 'dropout'],
    'bounds': [[0.0001, 0.1], [32, 256], [0.0, 0.5]]
}

# Analyse
sensitivity_results = optimizer.sensitivity_analysis(
    problem_def=problem,
    objective_func=objective,
    n_samples=1000
)
```

## üìä Visualisation des R√©sultats

### 1. R√©sultats de la Grille
- Distribution des scores par configuration
- Statistiques descriptives
- Identification des meilleures combinaisons

### 2. Optimisation Bay√©sienne
- Courbe de progression
- Exploration vs exploitation
- Convergence vers l'optimum

### 3. Analyse de Sensibilit√©
- Indices de premier ordre (S1)
- Indices totaux (ST)
- Interactions entre param√®tres

## üí° Bonnes Pratiques

1. **Pr√©paration**
   - D√©finir clairement l'objectif
   - Choisir les m√©triques appropri√©es
   - Pr√©parer les donn√©es de validation

2. **Ex√©cution**
   - Commencer par une recherche large
   - Affiner progressivement
   - Valider la robustesse

3. **Analyse**
   - Examiner les tendances
   - Identifier les param√®tres critiques
   - Documenter les r√©sultats

## üîç Exemples d'Utilisation Avanc√©e

### 1. Optimisation Multi-√©tapes
```python
# Premi√®re √©tape : recherche large
coarse_grid = {
    'hidden_layers': [[32], [64], [128]],
    'learning_rate': [0.1, 0.01, 0.001]
}
coarse_results = optimizer.grid_search(coarse_grid, objective)

# Deuxi√®me √©tape : optimisation fine
fine_bounds = [
    (coarse_results['learning_rate'] * 0.1, coarse_results['learning_rate'] * 10)
]
fine_results = optimizer.bayesian_optimization(fine_bounds, ['learning_rate'], objective)
```

### 2. Analyse de Robustesse
```python
# Test sur diff√©rents seeds
def robust_objective(params):
    scores = []
    for seed in [42, 123, 456]:
        np.random.seed(seed)
        model = NeuralNetwork(**params)
        scores.append(model.evaluate(X_test, y_test)['sharpe_ratio'])
    return np.mean(scores)

# Optimisation avec objectif robuste
robust_params = optimizer.grid_search(param_grid, robust_objective)
```

### 3. Optimisation Multi-objectifs
```python
def multi_objective(params):
    model = NeuralNetwork(**params)
    results = model.evaluate(X_test, y_test)
    return 0.6 * results['sharpe_ratio'] - 0.4 * results['max_drawdown']

pareto_params = optimizer.bayesian_optimization(param_bounds, param_names, multi_objective)
```

## ‚ö†Ô∏è Points d'Attention

1. **Co√ªt Computationnel**
   - √âquilibrer pr√©cision et temps de calcul
   - Utiliser le parall√©lisme quand possible
   - Monitorer l'utilisation des ressources

2. **Surapprentissage**
   - Valider sur des donn√©es ind√©pendantes
   - √âviter l'optimisation excessive
   - Maintenir une marge de s√©curit√©

3. **Interpr√©tation**
   - Analyser les interactions
   - Consid√©rer la stabilit√©
   - Valider les hypoth√®ses

## üìà M√©triques de Suivi

1. **Performance**
   - Score moyen
   - √âcart-type
   - Meilleur score

2. **Efficacit√©**
   - Temps de calcul
   - Nombre d'√©valuations
   - Taux de convergence

3. **Robustesse**
   - Stabilit√© des r√©sultats
   - Sensibilit√© aux param√®tres
   - G√©n√©ralisation 